{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reevafaisal/bluesky/blob/main/BlueSky.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**UPDATES:**\n",
        "- Drive setup code is saved in GitHub repo as *`drive_setup.py`*\n",
        "\n",
        "**NOTE:**\n",
        "- After every work session please push changes to the github repo to save work history: https://github.com/reevafaisal/bluesky\n",
        "- Please ensure there are no duplicate files in the repo."
      ],
      "metadata": {
        "id": "1IMFgbeuEzCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run cell for required packages and installations\n",
        "\n",
        "!pip install tqdm\n",
        "!pip install atproto\n",
        "!pip install atproto pandas requests tqdm\n",
        "from google.colab import drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "import tarfile\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import tarfile\n",
        "from atproto import Client\n",
        "import unicodedata\n",
        "import pandas as pd\n",
        "from requests.exceptions import RequestException\n",
        "import datetime\n",
        "from requests.exceptions import HTTPError\n",
        "import unicodedata"
      ],
      "metadata": {
        "id": "LcXYXBb6EK6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3126a98-2a39-4acf-e4b8-b93cba5bd8ae"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: atproto in /usr/local/lib/python3.11/dist-packages (0.0.58)\n",
            "Requirement already satisfied: click<9,>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from atproto) (8.1.8)\n",
            "Requirement already satisfied: cryptography<44,>=41.0.7 in /usr/local/lib/python3.11/dist-packages (from atproto) (43.0.3)\n",
            "Requirement already satisfied: dnspython<3,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from atproto) (2.7.0)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from atproto) (0.27.2)\n",
            "Requirement already satisfied: libipld<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from atproto) (3.0.0)\n",
            "Requirement already satisfied: pydantic<3,>=2.7 in /usr/local/lib/python3.11/dist-packages (from atproto) (2.10.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from atproto) (4.12.2)\n",
            "Requirement already satisfied: websockets<14,>=12 in /usr/local/lib/python3.11/dist-packages (from atproto) (13.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<44,>=41.0.7->atproto) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.25.0->atproto) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.25.0->atproto) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.25.0->atproto) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.25.0->atproto) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.25.0->atproto) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.25.0->atproto) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.7->atproto) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.7->atproto) (2.27.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<44,>=41.0.7->atproto) (2.22)\n",
            "Requirement already satisfied: atproto in /usr/local/lib/python3.11/dist-packages (0.0.58)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: click<9,>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from atproto) (8.1.8)\n",
            "Requirement already satisfied: cryptography<44,>=41.0.7 in /usr/local/lib/python3.11/dist-packages (from atproto) (43.0.3)\n",
            "Requirement already satisfied: dnspython<3,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from atproto) (2.7.0)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from atproto) (0.27.2)\n",
            "Requirement already satisfied: libipld<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from atproto) (3.0.0)\n",
            "Requirement already satisfied: pydantic<3,>=2.7 in /usr/local/lib/python3.11/dist-packages (from atproto) (2.10.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from atproto) (4.12.2)\n",
            "Requirement already satisfied: websockets<14,>=12 in /usr/local/lib/python3.11/dist-packages (from atproto) (13.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<44,>=41.0.7->atproto) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.25.0->atproto) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.25.0->atproto) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.25.0->atproto) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.25.0->atproto) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.7->atproto) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.7->atproto) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<44,>=41.0.7->atproto) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:**\n",
        "- we may no longer need to have access to the files, since we're directly crawling from the API.\n",
        "- maybe make a seperate drive account for file sharing?\n",
        "- do not forcibly remount, only uncomment and run if drive gets disconnected"
      ],
      "metadata": {
        "id": "JYXhiNmQF4Yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "s_FjqPRaGuTi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4ce1b2f-1c76-439f-f112-4bb7ebaedea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Account information**:\n",
        "  *   username: blueskyre.bsky.social\n",
        "  *   password: blueskyresearch"
      ],
      "metadata": {
        "id": "2KP1rtddBGHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_client():\n",
        "    client = Client()\n",
        "    try:\n",
        "        client.login(\"blueskyre.bsky.social\", \"blueskyresearch\")\n",
        "        print(\"âœ… Successfully authenticated to Bluesky API\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed to authenticate: {e}\")\n",
        "        return None\n",
        "    return client\n",
        "\n",
        "def normalize_uri(uri):\n",
        "  \"\"\"Normalize URIs: remove spaces, convert to lowercase, and normalize Unicode.\"\"\"\n",
        "  return unicodedata.normalize(\"NFKC\", uri.strip().lower())\n",
        "\n",
        "client = init_client()\n",
        "# print(client)\n",
        "\n",
        "feeds = client.app.bsky.unspecced.get_popular_feed_generators()\n"
      ],
      "metadata": {
        "id": "xWPe6zx2CbXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf0324e-6f30-4fc8-9b67-8ac94e08bd85"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Successfully authenticated to Bluesky API\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original `crawl_feed_bookmarks.py` script uses `otherfile.py` containing client information and the myfeeduris dictionary. Since it is not available in the publicly available file set, here are the methods used:\n",
        "\n",
        "*  `myfeeduris` (`dict`):\n",
        "  * first extracted all unique uris from entire feed.\n",
        "  * loaded them into a dict called `myfeeduris`\n",
        "\n",
        "* Using globally declared client.\n",
        "\n",
        "The code below is used to run the edited version of the crawl_feed_bookmarks.py file."
      ],
      "metadata": {
        "id": "d7ohTokkBe8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_uris = set()\n",
        "for f in feeds.feeds:\n",
        "    unique_uris.add(normalize_uri(f.uri))\n",
        "\n",
        "myfeeduris = {f\"Feed_{i+1}\": uri for i, uri in enumerate(unique_uris)}\n",
        "\n",
        "print(myfeeduris)"
      ],
      "metadata": {
        "id": "Lxr4Gw9VEKF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_likes(client, uri, cursor=None, likes=None):\n",
        "  cursor = None\n",
        "  old_cursor = None\n",
        "\n",
        "  if likes is None:\n",
        "      likes = []\n",
        "\n",
        "\n",
        "  while True:\n",
        "\n",
        "      try:\n",
        "          fetched = client.get_likes(uri, cursor=cursor, limit=100)\n",
        "          likes = likes + fetched.likes\n",
        "\n",
        "      except RequestException as e:\n",
        "          print(e)\n",
        "          cursor = old_cursor\n",
        "          continue\n",
        "      except HTTPError:\n",
        "          return []\n",
        "      except Exception as e:\n",
        "          print(f\"{datetime.datetime.now()} {e}\")\n",
        "          cursor = old_cursor\n",
        "          continue\n",
        "\n",
        "      if not fetched.cursor:\n",
        "          break\n",
        "\n",
        "      old_cursor = cursor\n",
        "      cursor = fetched.cursor\n",
        "\n",
        "  return likes\n",
        "\n",
        "\n",
        "def clean_like(like):\n",
        "    like = like.dict()\n",
        "    who = like['actor']['handle']\n",
        "    when = like['created_at']\n",
        "    return who, when\n",
        "\n",
        "\n",
        "def valid_time(t):\n",
        "    try:\n",
        "        T = datetime.datetime.fromisoformat(t)\n",
        "        if T.date() > datetime.datetime(2024, 3, 18).date():\n",
        "            return False\n",
        "        elif T.date() < datetime.datetime(2023, 2, 17).date():\n",
        "            return False\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "TqJz4VPg2pbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eaafe81-b67b-4051-eba5-1a23dcd5f8fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Successfully authenticated to Bluesky API\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** The cell below requires a long time to run!"
      ],
      "metadata": {
        "id": "LBWWZdliEU6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for f in feeds.feeds:\n",
        "    if f.uri.strip().lower() in set(myfeeduris.values()):\n",
        "        f = f.model_dump()\n",
        "        data.append([f['display_name'], f['uri'], f['creator']['handle'], f['indexed_at'], f['description']])\n",
        "        # break\n",
        "\n",
        "df = pd.DataFrame(data, columns=['display_name', 'uri', 'creator', 'indexed_at', 'description'])\n",
        "df.to_csv('feed_info_mine.csv', index=False, sep=';')\n",
        "\n",
        "with open('feed_likes_mine.csv', 'w') as f:\n",
        "    for name, uri in myfeeduris.items():\n",
        "        print(datetime.datetime.now(), name)\n",
        "        likes = collect_likes(client, uri)\n",
        "        for l in likes:\n",
        "            who, when = clean_like(l)\n",
        "            if valid_time(when):\n",
        "                f.write(f\"{name},{who},{when}\\n\")"
      ],
      "metadata": {
        "id": "zO8qrrCbEPhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The* code below is used to run the edited version of the `crawl_feed_bookmarks.py` file.\n",
        "\n",
        "**Note:** The cell below requires a long time to run!\n",
        "\n"
      ],
      "metadata": {
        "id": "QKDmNEHXE-gP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling `crawl_feed_post_likes.py`."
      ],
      "metadata": {
        "id": "jv-WEMzU7n8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run cell for required packages and installations\n",
        "\n",
        "import gzip\n",
        "import os\n",
        "import datetime\n",
        "from atproto_client import Client, SessionEvent\n",
        "from atproto.exceptions import RequestException, BadRequestError\n",
        "import datetime, time\n",
        "import gzip\n",
        "import os\n",
        "import logging.handlers\n",
        "import gzip\n",
        "import os\n",
        "import datetime\n",
        "from atproto_client import Client, SessionEvent\n",
        "from atproto.exceptions import RequestException, BadRequestError\n",
        "import datetime, time\n",
        "import gzip\n",
        "import os\n",
        "import logging.handlers\n",
        "import gzip"
      ],
      "metadata": {
        "id": "Xv9x-Z-IDu02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original File:\n",
        "*  Dependent on collection of `feed_uris`.\n",
        "*  `feed_uris` here likely represents the unique identifiers for ALL posts on the platform.\n",
        "\n",
        "Simplifying Assumption:\n",
        "\n",
        "\n",
        "*   Used the feeds currently accessible from the popular_feeds_generator.\n",
        "*   Our sample size right now is a lot smaller right now than it should be due to this assumption.\n",
        "* Using globally declared client\n",
        "\n",
        "TO DO:\n",
        "\n",
        "\n",
        "*   Dig through API to find a feed generator that sifts through all possible feeds.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7cmEafysGQ__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: Cell below takes ~30 secs to run."
      ],
      "metadata": {
        "id": "JFqpIyo29TJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for f in feeds.feeds:\n",
        "    feed_uri = normalize_uri(f.uri)\n",
        "    unique_post_uris = set()\n",
        "\n",
        "    try:\n",
        "        posts = client.app.bsky.feed.get_feed(params={\"feed\":feed_uri, \"limit\":50})\n",
        "        for post in posts.feed:\n",
        "            post_uri = normalize_uri(post.post.uri)\n",
        "            unique_post_uris.add(post_uri)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed to fetch posts for {feed_uri}: {e}\")\n",
        "\n",
        "feed_uris_dict = {f\"Post_{i+1}\": uri for i, uri in enumerate(unique_post_uris)}\n",
        "\n",
        "\n",
        "print(feed_uris_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5QH1fT00VvT",
        "outputId": "c71e4e2a-95d1-4bc1-816e-142f91220cec"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ Failed to fetch posts for at://did:plc:vc7f4oafdgxsihk4cry2xpze/app.bsky.feed.generator/media: Response(success=False, status_code=502, content=XrpcError(error='InvalidFeedResponse', message='feed provided an invalid response'), headers={'x-powered-by': 'Express', 'access-control-allow-origin': '*', 'cache-control': 'private', 'vary': 'Authorization, Accept-Encoding', 'ratelimit-limit': '3000', 'ratelimit-remaining': '2969', 'ratelimit-reset': '1738940840', 'ratelimit-policy': '3000;w=300', 'content-type': 'application/json; charset=utf-8', 'content-length': '77', 'etag': 'W/\"4d-NKHU+i0HaghYl3XdGRanj9ADYRE\"', 'date': 'Fri, 07 Feb 2025 15:02:35 GMT', 'keep-alive': 'timeout=90', 'strict-transport-security': 'max-age=63072000'})\n",
            "âŒ Failed to fetch posts for at://did:plc:2wqomm3tjqbgktbrfwgvrw34/app.bsky.feed.generator/authors: Response(success=False, status_code=502, content=XrpcError(error='InvalidFeedResponse', message='feed provided an invalid response'), headers={'x-powered-by': 'Express', 'access-control-allow-origin': '*', 'cache-control': 'private', 'vary': 'Authorization, Accept-Encoding', 'ratelimit-limit': '3000', 'ratelimit-remaining': '2957', 'ratelimit-reset': '1738940840', 'ratelimit-policy': '3000;w=300', 'content-type': 'application/json; charset=utf-8', 'content-length': '77', 'etag': 'W/\"4d-NKHU+i0HaghYl3XdGRanj9ADYRE\"', 'date': 'Fri, 07 Feb 2025 15:02:40 GMT', 'keep-alive': 'timeout=90', 'strict-transport-security': 'max-age=63072000'})\n",
            "{'Post_1': 'at://did:plc:o4gnmxjh5dyo7q3hpfpimczx/app.bsky.feed.post/3lhkddbzqmc2r', 'Post_2': 'at://did:plc:462mkz4bspd3k4iuwzngv6eh/app.bsky.feed.post/3lhkeihcg3k2p', 'Post_3': 'at://did:plc:rpty2ls6f4hmizzkajsnysb3/app.bsky.feed.post/3lhklqb4cys2y', 'Post_4': 'at://did:plc:qjijic4bjkx2vbvb5ljhpaoa/app.bsky.feed.post/3lhkmvgf4f223', 'Post_5': 'at://did:plc:ud4mbfwt7peg375w3x75vozp/app.bsky.feed.post/3lhkqbrf4fc2e', 'Post_6': 'at://did:plc:osdix43tq2pdr46ixgvnx36l/app.bsky.feed.post/3lhk535lsz222', 'Post_7': 'at://did:plc:gasv7nknoxqzcvqhizv5p55g/app.bsky.feed.post/3lhkncnfs7k25', 'Post_8': 'at://did:plc:g5ij2v24pfmmnmgysowm3yuf/app.bsky.feed.post/3lhjindynac23', 'Post_9': 'at://did:plc:mixdef3ii3valysmar4uhuln/app.bsky.feed.post/3lhlqc7j5u22n', 'Post_10': 'at://did:plc:iylglgevqgtj26u3rrckgxib/app.bsky.feed.post/3lhlqqtgt3c2o', 'Post_11': 'at://did:plc:kllsytqjwtuqsrgwtp3y6y3d/app.bsky.feed.post/3lhknfzcx6s2s', 'Post_12': 'at://did:plc:5d7smwzpzghnzeua5umb2k2u/app.bsky.feed.post/3lhk5tnppgs2i', 'Post_13': 'at://did:plc:fakngq67l47yamkpdhh7ye3c/app.bsky.feed.post/3lhkfhvdfum23', 'Post_14': 'at://did:plc:kgym4owrqbdhwdi7w3jbtrgq/app.bsky.feed.post/3lhkpmlaw5c2h', 'Post_15': 'at://did:plc:fpqaglnp4xapdeyfvynul6k5/app.bsky.feed.post/3lhknuj3fps2s', 'Post_16': 'at://did:plc:fakngq67l47yamkpdhh7ye3c/app.bsky.feed.post/3lhkfj5nvre23', 'Post_17': 'at://did:plc:fakngq67l47yamkpdhh7ye3c/app.bsky.feed.post/3lhkfibc7um23', 'Post_18': 'at://did:plc:lywwvbegz2lnfzlucxadztqm/app.bsky.feed.post/3lhknovlvq22w', 'Post_19': 'at://did:plc:7ann3lbekiejuldowt6iyg45/app.bsky.feed.post/3lhkgigwz722r', 'Post_20': 'at://did:plc:acabg22q7hcabzf66xwoucl6/app.bsky.feed.post/3lhjnxwtpn22d', 'Post_21': 'at://did:plc:kcrjokj3pxcrf5tmwydhlng5/app.bsky.feed.post/3lhkxhha4ms2j', 'Post_22': 'at://did:plc:kcrjokj3pxcrf5tmwydhlng5/app.bsky.feed.post/3lhkjs6wpas2s', 'Post_23': 'at://did:plc:rn6outvrrsypgrh3yqmxsu65/app.bsky.feed.post/3lhlt2rwiac2t', 'Post_24': 'at://did:plc:udzdncz54fsj2spg24u33wj2/app.bsky.feed.post/3lhjmgsfmwc2f', 'Post_25': 'at://did:plc:3ff4ctziecehxs6xvukslpq2/app.bsky.feed.post/3lhjqytyrl225', 'Post_26': 'at://did:plc:aqsu7agrchnmw7a2l3d3njgj/app.bsky.feed.post/3lhkcg6p7x22o', 'Post_27': 'at://did:plc:25vdlm3e334isjw3mdeqnhuv/app.bsky.feed.post/3lhlrhtra5k2y', 'Post_28': 'at://did:plc:lcytlkvzs3wslcgbk7i3ygak/app.bsky.feed.post/3lefsmffjqs27', 'Post_29': 'at://did:plc:4ebhh7ylkpupkin4ailwp5cz/app.bsky.feed.post/3lhldiqblyc2q', 'Post_30': 'at://did:plc:yn67wdnnk4mjl27h6rsxbwaj/app.bsky.feed.post/3lhkcghirpk26', 'Post_31': 'at://did:plc:kllsytqjwtuqsrgwtp3y6y3d/app.bsky.feed.post/3lhjopkl2t225', 'Post_32': 'at://did:plc:ud4mbfwt7peg375w3x75vozp/app.bsky.feed.post/3lhkz3mhimk2m', 'Post_33': 'at://did:plc:g5ij2v24pfmmnmgysowm3yuf/app.bsky.feed.post/3lhlac6ruw224', 'Post_34': 'at://did:plc:fakngq67l47yamkpdhh7ye3c/app.bsky.feed.post/3lhkfiuoz4423', 'Post_35': 'at://did:plc:mmgti3aluvnszzhgu3vmy6cd/app.bsky.feed.post/3lhkg65hsf227', 'Post_36': 'at://did:plc:gwgnjgvucvfy4hruw7vcf2a7/app.bsky.feed.post/3lhjxuqtma22q'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The file here is being saved to collab's virtual machine so there should\n",
        "# be no need to access google drive for this\n",
        "\n",
        "def save_feed_uris_to_file(post_uris, filename=\"feed_uris/popular_posts.txt.gz\"):\n",
        "    \"\"\"\n",
        "    Saves post URIs in a compressed .gz file for later processing.\n",
        "    \"\"\"\n",
        "    os.makedirs(\"feed_uris\", exist_ok=True)  # Ensure directory exists\n",
        "\n",
        "    with gzip.open(filename, \"wt\", encoding=\"utf-8\") as f:\n",
        "        for uri in feed_uris_dict.values():\n",
        "            f.write(uri + \"\\n\")\n",
        "\n",
        "    print(f\"âœ… Saved {len(post_uris)} post URIs to {filename}\")\n",
        "\n",
        "save_feed_uris_to_file(feed_uris_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwvlOm2b205f",
        "outputId": "4aa79cd5-274a-4935-b8db-941f968c9e8e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved 36 post URIs to feed_uris/popular_posts.txt.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"feed_uris/popular_posts.txt.gz\"\n",
        "with gzip.open(file_path, \"rt\", encoding=\"utf-8\") as f:\n",
        "    content = f.readlines()\n",
        "\n",
        "print(\"ðŸ“„ First 10 Saved Post URIs:\")\n",
        "print(\"\".join(content[:10]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUQPShGj7fkq",
        "outputId": "ee17aa4d-be50-4a7f-d5aa-43057cde8c0e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“„ First 10 Saved Post URIs:\n",
            "at://did:plc:o4gnmxjh5dyo7q3hpfpimczx/app.bsky.feed.post/3lhkddbzqmc2r\n",
            "at://did:plc:462mkz4bspd3k4iuwzngv6eh/app.bsky.feed.post/3lhkeihcg3k2p\n",
            "at://did:plc:rpty2ls6f4hmizzkajsnysb3/app.bsky.feed.post/3lhklqb4cys2y\n",
            "at://did:plc:qjijic4bjkx2vbvb5ljhpaoa/app.bsky.feed.post/3lhkmvgf4f223\n",
            "at://did:plc:ud4mbfwt7peg375w3x75vozp/app.bsky.feed.post/3lhkqbrf4fc2e\n",
            "at://did:plc:osdix43tq2pdr46ixgvnx36l/app.bsky.feed.post/3lhk535lsz222\n",
            "at://did:plc:gasv7nknoxqzcvqhizv5p55g/app.bsky.feed.post/3lhkncnfs7k25\n",
            "at://did:plc:g5ij2v24pfmmnmgysowm3yuf/app.bsky.feed.post/3lhjindynac23\n",
            "at://did:plc:mixdef3ii3valysmar4uhuln/app.bsky.feed.post/3lhlqc7j5u22n\n",
            "at://did:plc:iylglgevqgtj26u3rrckgxib/app.bsky.feed.post/3lhlqqtgt3c2o\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log = logging.getLogger(\"bot\")\n",
        "log.setLevel(logging.DEBUG)\n",
        "log.addHandler(logging.StreamHandler())\n",
        "\n",
        "def get_session():\n",
        "    try:\n",
        "        with open('session.txt') as f:\n",
        "            return f.read()\n",
        "    except FileNotFoundError:\n",
        "        return None\n",
        "\n",
        "\n",
        "def save_session(session_string):\n",
        "    with open('session.txt', 'w') as f:\n",
        "        f.write(session_string)\n",
        "\n",
        "\n",
        "def on_session_change(event, session):\n",
        "    print('Session changed:', event, repr(session))\n",
        "    if event in (SessionEvent.CREATE, SessionEvent.REFRESH):\n",
        "        print('Saving changed session')\n",
        "        save_session(session.export())\n",
        "\n",
        "def sleep_until(when):\n",
        "    now = datetime.datetime.now()\n",
        "    when = datetime.datetime.fromtimestamp(when, datetime.UTC)\n",
        "    if now.timestamp() > when.timestamp():\n",
        "        pass\n",
        "    else:\n",
        "        print(f\"waiting until {when}\")\n",
        "        time.sleep((when - now).total_seconds())\n",
        "\n",
        "\n",
        "def _handle_requests_exceptions(e):\n",
        "    status = e.response.status_code\n",
        "    print(f\"{datetime.datetime.now()}. error {status} {e.response.content.message}\")\n",
        "    if status == 429:\n",
        "        when = int(e.response.headers['RateLimit-Reset'])\n",
        "        sleep_until(when)\n",
        "\n",
        "    elif status in {409, 413, 502}:\n",
        "        time.sleep(50)\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "\n",
        "def _save(likes, file_id):\n",
        "\n",
        "    os.makedirs('feed_likes', exist_ok=True)\n",
        "\n",
        "    with gzip.open(f'feed_likes/{file_id}.csv.gz', 'a') as f:\n",
        "        for uri, post_author, ls in likes:\n",
        "            for like in ls:\n",
        "                user, created_at = clean_like(like)\n",
        "                row = f'{user},{post_author},{uri},{created_at}\\n'\n",
        "                f.write(row.encode('utf8'))\n",
        "\n",
        "\n",
        "\n",
        "def clean_like(like):\n",
        "    like = like.dict()\n",
        "    who = like['actor']['handle']\n",
        "    when = like['created_at']\n",
        "    return who, when\n",
        "\n",
        "\n",
        "def collect_likes(client, uri, cursor=None, likes=None):\n",
        "    cursor = None\n",
        "    old_cursor = None\n",
        "\n",
        "    if likes is None:\n",
        "        likes = []\n",
        "\n",
        "\n",
        "    while True:\n",
        "\n",
        "        try:\n",
        "            post_author = client.get_posts([uri]).posts[0].author.handle\n",
        "            fetched = client.get_likes(uri, cursor=cursor, limit=100)\n",
        "            likes = likes + fetched.likes\n",
        "\n",
        "        except RequestException as e:\n",
        "            _handle_requests_exceptions(e)\n",
        "            cursor = old_cursor\n",
        "            continue\n",
        "        except BadRequestError:\n",
        "            return None, []\n",
        "        except Exception as e:\n",
        "            print(f\"{datetime.datetime.now()} {e}\")\n",
        "            cursor = old_cursor\n",
        "            continue\n",
        "\n",
        "        if not fetched.cursor:\n",
        "            break\n",
        "\n",
        "        old_cursor = cursor\n",
        "        cursor = fetched.cursor\n",
        "\n",
        "    return post_author, likes\n",
        "\n",
        "\n",
        "for file in os.listdir('feed_uris'):\n",
        "    if file.endswith('.gz'):\n",
        "        uris = []\n",
        "\n",
        "        with gzip.open(os.path.join('feed_uris', file)) as f:\n",
        "            feed_name = file.replace('.txt.gz', '')\n",
        "            print('processing', feed_name)\n",
        "            all_likes = []\n",
        "            for l in f.readlines():\n",
        "                uri = l.decode('utf8').rstrip()\n",
        "                uris.append(uri)\n",
        "                post_author, likes = collect_likes(client, uri)\n",
        "                all_likes.append((uri, post_author, likes))\n",
        "            _save(all_likes, feed_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZGD1dp2F2dD",
        "outputId": "c78a6e0e-bb1a-4903-8684-4e2318df3a29"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing popular_posts\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-dd446664b0a3>:99: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  like = like.dict()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "\n",
        "file_path = \"/content/feed_likes/popular_posts.csv.gz\"\n",
        "\n",
        "with gzip.open(file_path, \"rt\", encoding=\"utf-8\") as f:\n",
        "    content = f.readlines()\n",
        "\n",
        "print(\"ðŸ“„ File Contents:\")\n",
        "print(\"\".join(content[:10]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NP-2H8HQ5TNb",
        "outputId": "dc8c6286-9b84-4e5a-b629-c0cf18f53a12"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“„ File Contents:\n",
            "sheyenne77.bsky.social,disposablewings.bsky.social,at://did:plc:o4gnmxjh5dyo7q3hpfpimczx/app.bsky.feed.post/3lhkddbzqmc2r,2025-02-07T02:33:31.035Z\n",
            "disposablewings.bsky.social,disposablewings.bsky.social,at://did:plc:o4gnmxjh5dyo7q3hpfpimczx/app.bsky.feed.post/3lhkddbzqmc2r,2025-02-07T01:03:20.578Z\n",
            "markhayden23.bsky.social,disposablewings.bsky.social,at://did:plc:o4gnmxjh5dyo7q3hpfpimczx/app.bsky.feed.post/3lhkddbzqmc2r,2025-02-07T00:51:26.650Z\n",
            "kasper24.bsky.social,disposablewings.bsky.social,at://did:plc:o4gnmxjh5dyo7q3hpfpimczx/app.bsky.feed.post/3lhkddbzqmc2r,2025-02-07T00:22:23.870Z\n",
            "astravelious.bsky.social,tinyteerex.bsky.social,at://did:plc:462mkz4bspd3k4iuwzngv6eh/app.bsky.feed.post/3lhkeihcg3k2p,2025-02-07T01:16:11.904Z\n",
            "pastorkathleen.bsky.social,otheredones.bsky.social,at://did:plc:rpty2ls6f4hmizzkajsnysb3/app.bsky.feed.post/3lhklqb4cys2y,2025-02-07T13:33:01.106Z\n",
            "mxfee.bsky.social,otheredones.bsky.social,at://did:plc:rpty2ls6f4hmizzkajsnysb3/app.bsky.feed.post/3lhklqb4cys2y,2025-02-07T08:51:08.966Z\n",
            "maiar.bsky.social,otheredones.bsky.social,at://did:plc:rpty2ls6f4hmizzkajsnysb3/app.bsky.feed.post/3lhklqb4cys2y,2025-02-07T08:17:54.118Z\n",
            "skye-akimbo.bsky.social,otheredones.bsky.social,at://did:plc:rpty2ls6f4hmizzkajsnysb3/app.bsky.feed.post/3lhklqb4cys2y,2025-02-07T08:13:39.756Z\n",
            "otheredones.bsky.social,otheredones.bsky.social,at://did:plc:rpty2ls6f4hmizzkajsnysb3/app.bsky.feed.post/3lhklqb4cys2y,2025-02-07T06:06:34.412Z\n",
            "\n"
          ]
        }
      ]
    }
  ]
}